# Project1

### é¢˜ç›®è¦æ±‚ï¼š

```
In this project, you are supposed to create your own mini search engine which can handle inquiries over â€œThe Complete Works of William Shakespeareâ€ (http://shakespeare.mit.edu/).

You may download the functions for handling stop words and stemming from the Internet, as long as you add the source in your reference list.

Your tasks are:
(1) Run a word count over the Shakespeare set and try to identify the stop words (also called the noisy words) â€“ How and where do you draw the line between â€œinterestingâ€ and â€œnoisyâ€ words?
(2) Create your inverted index over the Shakespeare set with word stemming. The stop words identified in part (1) must not be included.
(3) Write a query program on top of your inverted file index, which will accept a user-specified word (or phrase) and return the IDs of the documents that contain that word.
(4) Run tests to show how the thresholds on query may affect the results.


Grading Policy:
Programming: Write the programs for word counting (1 pt.), index generation (5 pts.) and query processing (3 pts.) with sufficient comments.

Testing: Design tests for the correctness of the inverted index (2 pts.) and thresholding for query (2 pts.). Write analysis and comments (3 pts.). Bonus: What if you have 500 000 files and 400 000 000 distinct words? Will your program still work? (+2 pts.)

Documentation: Chapter 1 (1 pt.), Chapter 2 (2 pts.), and finally a complete report (1 point for overall style of documentation).

Note: Anyone who does excellent job on answering the Bonus question will gain extra points.
```

[èå£«æ¯”äºšå…¨é›†repoï¼Œä½†æ˜¯æ˜¯htmlç‰ˆ](https://kkgithub.com/TheMITTech/shakespeare)

[æ¥è‡ªKaggleçš„dataset](https://www.kaggle.com/datasets/kewagbln/shakespeareonline)

## 1 çŸ¥è¯†å‚¨å¤‡ & æ•´ç†

### 1.1 Makefile

ä¸ªäººæ„Ÿè§‰å†™å¾—è¶…çº§å¥½çš„Makefileæ•™ç¨‹->[æŒ‡è·¯çŸ¥ä¹](https://zhuanlan.zhihu.com/p/618350718)

åæ­£æœ€ååªè¦ä¸€ä¸ªäººå†™å°±è¡Œäº†ï¼ˆ

### 1.2 Stemmingå’Œstop words

- åœ¨å¾€å¹´ï¼ˆæŒ‡4å¹´å‰ï¼Œæ±—ï¼‰çš„[project](https://kkgithub.com/haoliu97/mini-search-engine.git)ä¸­æ‰¾åˆ°çš„è¢«å¼•ç”¨çš„stemmerï¼š[porter2_stemmer](https://kkgithub.com/smassung/porter2_stemmer/tree/master/util)ï¼Œ æ—¢ç„¶æœ‰äººç”¨è¿‡è¯´æ˜æ˜¯ç¡®å®å¯ä»¥ç”¨çš„ï¼ä½†æ˜¯å”¯ä¸€çš„é—®é¢˜å°±æ˜¯ï¼Œè¿™ä¸ªæ–‡ä»¶é€‚é…C++è€Œä¸æ˜¯Cã€‚åœ¨githubä¸Šæ‰¾åˆ°çš„å¯ä»¥ç”¨çš„ç°æˆstemmeræœ‰ï¼š

  - [snowball stmmer](https://kkgithub.com/snowballstem/snowball)ï¼ŒGitHubä¸ŠğŸŒŸæœ€å¤šçš„ï¼Œä½†æ˜¯å°äººå®åœ¨çœ‹ä¸æ‡‚

  - [porter stemmer](https://kkgithub.com/wooorm/stmr.c)ï¼Œè½»é‡ï¼Œç”¨èµ·æ¥å¾ˆæ–¹ä¾¿ï¼Œç›´æ¥`#include "stmr.h"`å³å¯ï¼Œå…·ä½“è¡¨ç°ä¸æ¸…æ¥šã€‚æˆ‘è‡ªå·±åœ¨Cé‡Œé¢è¯•äº†ä¸€ä¸‹ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨

    - ```C
      #include <stdio.h>
      #include <string.h>
      #include "stmr.h"
      
      
      int main(int argc, const char * argv[]) {
          // insert code here...
          char w[20] = "stopped";
          char *word = w;
          int end = stem(word, 0, strlen(word) - 1);
          word[end + 1] = 0;
          printf("%s\n", word);
          return 0;
      }
      //è¾“å‡ºï¼šstop
      ```

    - 

  - [snowball stemmer](https://kkgithub.com/tebeka/snowball)ï¼Œæ¯”è¾ƒå¤æ‚ï¼Œå¯èƒ½è¡¨ç°ä¼šç¨å¾®å¥½ä¸€ç‚¹ï¼Ÿä½†æ˜¯æ„Ÿè§‰è°ƒç”¨æ¯”è¾ƒéº»çƒ¦ï¼ˆæˆ‘çœ‹ä¸æ‡‚ï¼‰ï¼š

    - ```c
      package snowball_test
      
      import (
      	"fmt"
      
      	"github.com/tebeka/snowball"
      )
      
      func Example() {
      	stemmer, err := snowball.New("english")
      	if err != nil {
      		fmt.Println("error", err)
      		return
      	}
      	defer stemmer.Close()
      
      	fmt.Println(stemmer.Stem("worked"))
      	fmt.Println(stemmer.Stem("working"))
      	fmt.Println(stemmer.Stem("works"))
      	// Output:
      	// work
      	// work
      	// work
      }
      ```

  - è¿˜æœ‰ä¸€äº›ruby stemmerï¼Œæ„Ÿè§‰ä¸æ˜¯å¾ˆæ‡‚ï¼Œä¼¼ä¹ä¸æ˜¯ç»™æˆ‘ä»¬è¿™ç§å°ç™½ç”¨çš„

  - Stemmer for pythonï¼Œpythonä½œä¸ºå¤‡é€‰è¯­è¨€ï¼Œæˆ‘ä¹Ÿæ‰¾äº†ä¸€äº›stemmer

    - [porter2](https://kkgithub.com/mdirolf/pyporter2)

    - è°ƒç”¨ä»£ç ï¼š

      ```python
      if __name__ == '__main__':
          word = 'wolves'
          # print(stemmer.PorterStemmer().stem('ourselves'))
          print(Porter2Stemmer.Stemmer('english').stemWord('consistant'))
      ```

    - ä½†æ˜¯å¤§å¤šæ•°porter2 stemmeréƒ½æœ‰ä¸€ä¸ªé—®é¢˜ï¼šä¸èƒ½å°†-vesç±»å‹stemæˆæ­£å¸¸ç±»å‹ã€‚ä¹Ÿå°±æ˜¯'wolves'å’Œ'wolf'ä¸èƒ½æŠ½è±¡åˆ°ä¸€ä¸ªå•è¯ã€‚ä½†æ˜¯æ ¹æ®stemmingçš„å®šä¹‰ï¼Œç”šè‡³ä»–ä»¬å¯èƒ½ä¸éœ€è¦å˜æˆåŒä¸€ä¸ªå•è¯ï¼ˆæ¯•ç«Ÿå¤æ•°å’Œå•æ•°æœ¬å°±ä¸æ˜¯ä¸€ä¸ªæ„æ€å¯¹å—ï¼Ÿï¼‰
    
    - pythonè‡ªå¸¦åº“[NLTK](https://www.cnblogs.com/Patrick-L/p/12251747.html)ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå¿½ç•¥stop words + stemmingçš„æ“ä½œï¼Œæœ‰å¤šç§stemmingç®—æ³•ï¼ˆporter / snowballï¼‰å¯ä»¥é€‰æ‹©ï¼š
    
      ```python
      >>> from nltk.stem.snowball import SnowballStemmer
      >>> print(" ".join(SnowballStemmer.languages))
      danish dutch english finnish french german hungarian italian
      norwegian porter portuguese romanian russian spanish swedish
      
      >>> stemmer = SnowballStemmer("english")
      >>> print(stemmer.stem("running"))
      run
      
      >>> stemmer2 = SnowballStemmer("english", ignore_stopwords=True)
      >>> print(stemmer.stem("having"))
      have
      >>> print(stemmer2.stem("having"))
      having
      
      >>> print(SnowballStemmer("english").stem("generously"))
      generous
      >>> print(SnowballStemmer("porter").stem("generously"))
      gener
      ```
    
    - åœ¨å®‰è£…nltkå’Œ`nltk.download('stopwords')`æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè§£å†³æ–¹æ³•[å‚è€ƒæ­¤åšå®¢](https://blog.csdn.net/qq_45571138/article/details/121064447). ä½†æ˜¯è¿™ä¸ªsnowballäº²æµ‹ä¸å¥½ç”¨â€¦â€¦ç¬¬ä¸€ï¼Œ`ignore_stopword = True`ï¼Œä½†æ˜¯å±ç”¨æ²¡æœ‰ï¼›ç¬¬äºŒï¼ŒnltkåŒ…å†…å®¹æ˜¯ä¸å¯è§çš„ï¼Œä¹Ÿå°±æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½ä¿®æ”¹å‡½æ•°çš„ç»†èŠ‚ï¼Œæ™ºèƒ½é¡ºåº”åŒ…çš„è§„èŒƒï¼›
    

- stop words, GitHubä¸Šæœ‰å¾ˆå¤šè‹±è¯­stop wordsçš„ç°æˆè¡¨æ ¼

  - [å¾ˆå¤šä¸åŒæ ‡å‡†çš„è‹±è¯­stopwordsè¡¨](https://kkgithub.com/stopwords-iso/stopwords-en)
  - ä½†æ˜¯é—®é¢˜åœ¨äºâ€œHow and where do you draw the line between â€œinterestingâ€ and â€œnoisyâ€ words?â€ï¼Œä¾‹å¦‚"to be or not to be"ã€‚æˆ‘æŸ¥äº†ç½‘ä¸Šï¼Œä¼¼ä¹ä¹Ÿæ²¡ä»€ä¹ˆå¥½çš„è§£å†³åŠæ³•â€¦â€¦
  - å¤§å®¶åŸºæœ¬ä¸Šé€‰æ‹©ç›´æ¥å°†åœç”¨è¯åˆ é™¤

- pythoné…ç½®æœ‰ç°æˆçš„NLTKï¼ˆè‡ªç„¶è¯­è¨€å·¥å…·åŒ…ï¼‰å¯ä»¥å¤„ç†åˆ é™¤åœç”¨è¯ï¼Œç›´æ¥è°ƒç”¨å³å¯ï¼š

  ```python
  from nltk.corpus import stopwords 
  from nltk.tokenize import word_tokenize 
  
  example_sent = "This is a sample sentence, showing off the stop words filtration."
  
  stop_words = set(stopwords.words('english')) 
  
  word_tokens = word_tokenize(example_sent) 
  
  filtered_sentence = [w for w in word_tokens if not w in stop_words] 
  
  print(word_tokens) 
  print(filtered_sentence) 
  
  # è¾“å‡ºï¼š
  # ['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']
  # ['This', 'sample', 'sentence', ',', 'showing', 'stop','words', 'filtration', '.']
  # å‚è€ƒåšå®¢ï¼šhttps://blog.csdn.net/miaoxiaowuseng/article/details/107343427
  ```

### 1.3 Word Count

WordCountæ˜¯ä¸€ç§å¸¸è§çš„æ–‡æœ¬å¤„ç†ä»»åŠ¡ï¼Œç”¨äºè®¡ç®—ç»™å®šæ–‡æœ¬ä¸­å•è¯çš„æ•°é‡ã€‚å®ƒå¯ä»¥ç”¨äºç»Ÿè®¡æ–‡ç« ã€æŠ¥å‘Šæˆ–å…¶ä»–æ–‡æ¡£ä¸­å•è¯çš„å‡ºç°é¢‘ç‡ã€‚

### 1.3.1 ç”¨ä»€ä¹ˆè¯­è¨€

- pythonåœ¨å¤„ç†å­—ç¬¦ä¸²æ–¹é¢å…·æœ‰å¾ˆè‰¯å¥½çš„æ€§è´¨ï¼Œç»“æ„ä¹Ÿæ›´åŠ ç®€å•

  - çŸ­çŸ­ä¸€æ®µä»£ç å°±å¯ä»¥å®ç°word countçš„åŠŸèƒ½ï¼›

    ```python
    def word_count(text):
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œå¹¶å°†æ ‡ç‚¹ç¬¦å·æ›¿æ¢ä¸ºç©ºæ ¼
        text = text.lower().replace(",", " ").replace(".", " ").replace("!", " ").replace("?", " ")
     
        # åˆ©ç”¨ç©ºæ ¼å°†æ–‡æœ¬åˆ†å‰²æˆå•è¯åˆ—è¡¨
        words = text.split()
     
        # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªå•è¯çš„è®¡æ•°
        word_count = {}
     
        # éå†å•è¯åˆ—è¡¨ï¼Œç»Ÿè®¡æ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°
        for word in words:
            if word in word_count:
                word_count[word] += 1
            else:
                word_count[word] = 1
     
        return word_count
     
    # ç¤ºä¾‹ç”¨æ³•
    text = "This is a sample sentence. This sentence is used for word count example."
    result = word_count(text)
    print(result)
    print(result.keys())
    print(result.get('this'))
    print(result.popitem())
    
    #{'this': 2, 'is': 2, 'a': 1, 'sample': 1, 'sentence': 2, 'used': 1, 'for': 1, 'word': 1, 'count': 1, 'example': 1}
    #dict_keys(['this', 'is', 'a', 'sample', 'sentence', 'used', 'for', 'word', 'count', 'example'])
    #2
    #('example', 1)
    ```

  - pythonæ–‡ä»¶ä¹‹é—´çš„ç›¸äº’å¼•ç”¨æ¯”è¾ƒæ–¹ä¾¿ï¼Œä¸€ä¸ª`import`å³å¯æå®šï¼Œä¸å­˜åœ¨æ˜¯å¦éœ€è¦æŒ‰é¡ºåºç¼–è¯‘çš„æƒ…å†µï¼Œå¦‚æœæ˜¯åœ¨åŒçº§ç›®å½•ä¸‹ç”šè‡³ä¸ç”¨è€ƒè™‘è·¯å¾„é—®é¢˜ï¼›

  - pythonå¯ä»¥ç›´æ¥ä½¿ç”¨å¤§é‡çš„NLPï¼ˆNatural Language Processï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰åº“ï¼Œé€šè¿‡ä¸‹è½½å`import`å³å¯è®¿é—®ï¼Œæœ‰äº›è‡ªåŠ¨æœ‰åˆ¤æ–­stopwordsçš„åŠŸèƒ½ï¼›

  - Pythonçš„dictionaryç»“æ„åŠŸèƒ½éå¸¸é½å…¨ï¼Œå…·ä½“åŠŸèƒ½åŒ…æ‹¬ä½†ä¸é™äºï¼š

    - å¯ä»¥ç›´æ¥æ ¹æ®keyï¼ˆå­—ç¬¦ä¸²ï¼‰æœç´¢å¯¹åº”çš„valueï¼ˆæ•°å€¼ï¼‰: `.get('key')`

    - ç›´æ¥å¾—åˆ°æ‰€æœ‰keysçš„é›†åˆ: `.keys()`

    - dict + forï¼Œå¯ä»¥ç›´æ¥å®Œæˆword countçš„å åŠ 

      ```python
      for k in result.keys():
        tries[k] += result.get(k)
      ```

  - python ä¸­çš„testå†™èµ·æ¥æ¯”è¾ƒæ–¹ä¾¿ï¼Œä¸éœ€è¦å•ç‹¬çš„æ–‡ä»¶å­˜æ”¾ï¼Œå½“ç„¶ä¹Ÿä¸éœ€è¦æŒ‡å®šç¼–è¯‘é¡ºåºã€‚ä¸€ä¸ªå…¸å‹pythonæµ‹è¯•æ–‡ä»¶çš„å†™æ³•å¦‚ä¸‹ï¼š

    ```python
    class A:
      # å®šä¹‰å‡½æ•°
    	def func(self, var1, var2, ...):
        ...
        return ...
      
      # å®šä¹‰testï¼Œè¿™ä¸ªå‡½æ•°æ˜¯å¯ä»¥ç›´æ¥è¿è¡Œçš„
      def func_test(self):
        self.assertEqual(func(a, b), expected_output) #å¦‚æœä¸¤è¾¹ä¸ç›¸ç­‰ï¼Œtestä¼šæŠ¥é”™ï¼Œèƒ½æ¸…æ¥šçœ‹åˆ°å“ªä¸ªcaseé”™äº†
    ```

    ä¸€ä¸ªæ–‡ä»¶ä¸­å¯ä»¥ç¼–å†™å¤šä¸ªtest functionï¼Œå¤§é‡æµ‹è¯•ã€‚

- Cï¼Œé™¤äº†å’±ä»¬æŒæ¡çš„æ¯”è¾ƒç†Ÿç»ƒï¼Œæˆ‘æƒ³ä¸å‡ºæ¥æœ‰ä»€ä¹ˆç‰¹åˆ«çš„ä¼˜åŠ¿â€¦â€¦Cæœ¬èº«ä¸æ”¯æŒstringç±»å‹ï¼Œåœ¨æ–‡æœ¬å¤„ç†æ—¶éš¾å…ä¼šé‡åˆ°é€šç¯‡éƒ½æ˜¯æŒ‡é’ˆçš„æƒ…å†µã€‚è€ŒæŒ‡é’ˆâ€¦â€¦ddddï¼Œæ¯”è¾ƒå®¹æ˜“å‡ºé”™ã€éš¾ä»¥ç®¡ç†
  - å¦‚æœè¦ä½¿ç”¨Cçš„è¯ï¼Œword parseè‚¯å®šéœ€è¦å•ç‹¬ä¸€ä¸ªå‡½æ•°



## 2. æ•°æ®ç»“æ„ & å·¥ç¨‹æ¶æ„

### 2.1 æ•°æ®ç»“æ„

- **ç”¨ä»€ä¹ˆæ•°æ®ç»“æ„å­˜æ”¾termsï¼Ÿ**è¿™æ˜¾ç„¶æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ã€‚
  - æ ‘
    
  - åŠ¨æ€hash table
    - åœ¨hash codeåˆ†é…å¾—è¶³å¤Ÿå¹³å‡çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿å¾—æ’å…¥å’Œåˆ é™¤çš„å¤æ‚åº¦ä¸º$O(1)$ï¼ˆæ‚¨çŒœæ€ä¹ˆç€ï¼Œpythoné‡Œæ­£å¥½æœ‰ç›´æ¥ç”Ÿæˆhashcodeçš„å‡½æ•°å‘¢ï¼ï¼‰
    
  - tries
  - pythonå­—å…¸

â€‹	æˆ‘ä¸ªäººæœ€æ¨èTireï¼ˆå­—å…¸æ ‘ï¼‰ï¼ˆè¿™åå­—ä¸€å¬å°±æ˜¯ä¸ºäº†å¤„ç†æ–‡æœ¬è®¾è®¡çš„ï¼ï¼ä¸æ˜¯ä¹ˆï¼Ÿï¼Ÿï¼ï¼‰

â€‹	æ¥è‡ª[wikiçš„å­—å…¸æ ‘](https://oi-wiki.org/string/trie/)ï¼ŒåŒ…å«äº†å­—å…¸æ ‘çš„ç”Ÿæˆã€æŸ¥è¯¢ç­‰ä»£ç ï¼ˆä»…æœ‰C++ä¸Pythonç‰ˆæœ¬ï¼‰

```python
class trie:
    def __init__(self):
        self.nex = [[0 for i in range(26)] for j in range(100000)]
        self.cnt = 0
        self.exist = [False] * 100000  # è¯¥ç»“ç‚¹ç»“å°¾çš„å­—ç¬¦ä¸²æ˜¯å¦å­˜åœ¨

    def insert(self, s):  # æ’å…¥å­—ç¬¦ä¸²
        p = 0
        for i in s:
            c = ord(i) - ord('a')
            if not self.nex[p][c]:
                self.cnt += 1
                self.nex[p][c] = self.cnt  # å¦‚æœæ²¡æœ‰ï¼Œå°±æ·»åŠ ç»“ç‚¹
            p = self.nex[p][c]
        self.exist[p] = True

    def find(self, s):  # æŸ¥æ‰¾å­—ç¬¦ä¸²
        p = 0
        for i in s:
            c = ord(i) - ord('a')
            if not self.nex[p][c]:
                return False
            p = self.nex[p][c]
        return self.exist[p]
```

â€‹	å¦‚æœä½¿ç”¨å­—å…¸æ ‘ï¼Œå¯ä»¥å®Œæˆå¾ˆå¤šextraçš„åŠŸèƒ½ï¼šæŸ¥è¯¢æ‹¥æœ‰åŒæ ·prefixçš„termsç­‰ã€‚



- **ç”¨ä»€ä¹ˆç»“æ„å­˜æ”¾inverted indexï¼Ÿ**

  æ¯ä¸ªtermå¯¹åº”çš„inverted indexï¼Œè¯¥å¦‚ä½•å’Œtermè”ç³»åœ¨ä¸€èµ·ï¼Ÿ

  - pythonè‡ªå¸¦çš„dictionaryç±»å‹å¯ä»¥å®ç°è¿™æ ·çš„ç»“æ„ï¼š

    ```python
    			#             A
          #           /    \
          #          D      P
          #         / \
          #        D   A    æ­¤å¤„Dã€Aä¸ºå°¾èŠ‚ç‚¹
          #        |   |
          # dict{'document1': time1, 'document2': time2, ...}
    ```

    - å¦‚æœåªè¦å®ç°word countï¼Œæˆ‘ä»¬ç”šè‡³å¯ä»¥ä¸ç”¨ç‰¹å®šçš„æ•°æ®ç»“æ„å‚¨å­˜termsï¼Œç›´æ¥ä½¿ç”¨`dict{'term1', dict{'document1.1', time1.1, 'document1.2', time1.2, ...}, 'term2', dict{'document2.1', time2.1, 'document2.2', time2.2, ...}, ...}`è¿™æ ·å­—å…¸é‡Œé¢å¥—å­—å…¸çš„ç»“æ„è¿›è¡Œå‚¨å­˜ï¼ˆGodè¿™ä¼šæœ‰å¤šä¹ˆæ–¹ä¾¿ï¼ï¼‰

  - é“¾è¡¨

  - æ•°ç»„

### 2.2 å·¥ç¨‹æ¶æ„ - åº”è¯¥æœ‰å‡ ä¸ªæ–‡ä»¶ï¼Ÿåˆ†åˆ«å®ç°æ€æ ·çš„åŠŸèƒ½ï¼Ÿ

- document parse
  - å°†å¤§é‡çš„æ–‡ä»¶/å¾ˆå¤§çš„å•ä¸ªæ–‡ä»¶æŒ‰ç…§document nameåˆ†æˆå¯ä»¥ç›´æ¥ç»™pretreatå¤„ç†çš„æ ¼å¼ï¼Œæ¯”å¦‚æŒ‰ç…§è‡ªç„¶æ®µåˆ†å‰²ã€æŒ‰ç…§å¥å­åˆ†å‰²ã€æŒ‰ç…§å•è¯åˆ†å‰²ç­‰
    - [pythonè‹±æ–‡åˆ†å¥ï¼Œæ®µè½->å¥å­](https://blog.csdn.net/weixin_39450145/article/details/112973381)
    - [pythonè‹±æ–‡åˆ†å±€ï¼Œå¥å­->å•è¯](https://blog.csdn.net/weixin_44749822/article/details/124740549)
    - [pythonè¯»å–ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶](https://blog.csdn.net/LZGS_4/article/details/50371030)
    - [pythonè¯»å–ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ä»¶çš„æ–‡ä»¶å](https://blog.csdn.net/zhuzuwei/article/details/79925562)
  - document parseçš„å…·ä½“æ­¥éª¤åº”è¯¥æ˜¯ï¼š
    1. å…ˆè¯»å–èå£«æ¯”äºšå…¨é›†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åï¼Œåšæˆä¸€ä¸ªdictï¼Œè¿™æ ·å¯ä»¥æ ¹æ®æ–‡ä»¶åæŸ¥è¯¢åˆ°æ–‡ä»¶idï¼š`{document_name: id}`
    2. å†éå†dictï¼Œç”¨word_counterå¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼ŒåŒæ—¶è¿›è¡Œpretreatã€å°†termsåŠ å…¥trie
  - è¿”å›ä¸€ä¸ªå¯ä»¥ç›´æ¥ä¼ ç»™pretreatå¤„ç†çš„æ•°æ®ç»“æ„
- pretreat(stemming & stopwords)
  - ç”¨stopwordåŠŸèƒ½å»é™¤æ‰€æœ‰stopwords
  - ç”¨stemmingå°†æ‰€æœ‰çš„å•è¯è¯å¹²æå–
  - è¿™ä¸€æ­¥åº”è¯¥è¿”å›çš„æ˜¯å•è¯çš„é›†åˆ
- word count & index generation
  - å‚¨å­˜termçš„æ•°æ®ç»“æ„åº”è¯¥åœ¨è¿™ä¸€éƒ¨åˆ†å®Œæˆ
  - åˆ©ç”¨ä¸Šä¸€æ­¥è¿”å›çš„å•è¯çš„é›†åˆï¼Œè¿›è¡Œword count
  - å¦‚æœword countè¿”å›ä¸€ä¸ªdictionaryï¼Œå°±å¯ä»¥ç›´æ¥è¿›è¡Œindex generation
  - è¿”å›ä¸€ä¸ªdict/trie/whatever...
- Query
  - å‰å‡ ä¸ªæ–‡ä»¶çš„å†…å®¹æ˜¯ç¼–å†™å‡½æ•°å’Œtest caseï¼Œè¿™ä¸ªæ–‡ä»¶çš„ä½œç”¨æ˜¯è°ƒç”¨å’Œè¿”å›ç»“æœï¼ˆç†è®ºä¸Šæ¥è¯´å‰é¢å‡ ä¸ªæ–‡ä»¶å¯ä»¥æ²¡æœ‰ä»»ä½•è¾“å‡ºï¼‰
  - å°†æ‰€æœ‰å‰é¢çš„æ–‡ä»¶importè¿›æ¥
  - `parsed = document_parse('./shakespera.txt')`ï¼Œ `pretreated = pretreat(parsed)`ï¼Œ `result = wordcount_indexgen(pretreated)`ï¼Œ `find(result, 'term')`ã€‚
  
  ```
  import pretreat
  import word_count
  
  Tire = word_count(pretreat('./shakepeara.txt'))
  input = ç”¨æˆ·è¾“å…¥çš„å•è¯
  if (Trie.find(intput) = True):
  	return Trie.get(intput).keys()
  else :
  	print('æ­¤å•è¯ä¸å­˜åœ¨')
  ```
  
  

